{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "description: Dealing with transformations (groups, appending, replacing, freezing).\n",
    "---\n",
    "\n",
    "# Advanced Transformations\n",
    "AvalancheDataset (and its subclasses like the Avalanche*Tensor/Subset/Concat*Dataset) allow for a finer control over transformations. While torchvision (and other) datasets allow for a minimal mechanism to apply transformations, with AvalancheDataset one can:\n",
    "1. Have multiple **transformation \"groups\"** in the same dataset (like separated train and test transformations).\n",
    "2. **Append, replace and remove transformations**, even by using nested Subset/Concat Datasets.\n",
    "3. **Freeze transformations**, so that they can't be changed.\n",
    "\n",
    "The following sub-sections show examples on how to use these features. Please note that all the constructor parameters and the methods described in this How-To can be used on AvalancheDataset subclasses as well. For more info on all the available subclasses, refer to [this Mini How-To](https://avalanche.continualai.org/how-tos/avalanchedataset/creating-avalanchedatasets).\n",
    "\n",
    "It is warmly recommended to **run this page as a notebook** using Colab (info at the bottom of this page).\n",
    "\n",
    "Let's start by installing Avalanche:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install avalanche-lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation groups\n",
    "AvalancheDatasets can contain multiple **transformation groups**. This can be useful to keep train and test transformations in the same dataset and to have different set of transformations. This may come in handy in many situations (for instance, to apply ad-hoc transformations to replay data).\n",
    "\n",
    "As in torchvision datasets, AvalancheDataset supports the two kind of transformations: the `transform`, which is applied to X values, and the `target_transform`, which is applied to Y values. The latter is rarely used. This means that **a transformation group is a pair of transformations to be applied to the X and Y values** of each instance returned by the dataset. In both torchvision and Avalanche implementations, **a transformation must be a function (or other callable object)** that accepts one input (the X or Y value) and outputs its transformed version. This pair of functions is stored in the `transform` and `target_transform` fields of the dataset. A comprehensive guide on transformations can be found in the [torchvision documentation](https://pytorch.org/vision/stable/transforms.html).\n",
    "\n",
    "In the following example, a MNIST dataset is created and then wrapped in an AvalancheDataset. When creating the AvalancheDataset, we can set *train* and *eval* transformations by passing a *transform\\_groups* parameter. Train transformations usually include some form of random augmentation, while eval transformations usually include a sequence of deterministic transformations only. Here we define the sequence of train transformations as a random rotation followed by the ToTensor operation. The eval transformations only include the ToTensor operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from avalanche.benchmarks.utils import AvalancheDataset\n",
    "\n",
    "mnist_dataset = MNIST('mnist_data', download=True)\n",
    "\n",
    "# Define the training transformation for X values\n",
    "train_transformation = transforms.Compose([\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "# Define the training transformation for Y values (rarely used)\n",
    "train_target_transformation = None\n",
    "\n",
    "# Define the test transformation for X values\n",
    "eval_transformation = transforms.ToTensor()\n",
    "# Define the test transformation for Y values (rarely used)\n",
    "eval_target_transformation = None\n",
    "\n",
    "transform_groups = {\n",
    "    'train': (train_transformation, train_target_transformation),\n",
    "    'eval': (eval_transformation, eval_target_transformation)\n",
    "}\n",
    "\n",
    "avl_mnist_transform = AvalancheDataset(mnist_dataset, transform_groups=transform_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, one can also just use the `transform` and `target_transform` constructor parameters to set the transformations for both the *train* and the *eval* groups. However, it is recommended to use the approach based on *transform\\_groups* (shown in the code above) as it is much more flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not recommended: use transform_groups instead\n",
    "avl_mnist_same_transforms =  AvalancheDataset(mnist_dataset, transform=train_transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `.train()` and `.eval()`\n",
    "\n",
    "**The default behaviour of the AvalancheDataset is to use transformations from the _train_ group.** However, one can easily obtain a version of the dataset where the *eval* group is used. Note: when obtaining the dataset of experiences from the test stream, those datasets will already be using the *eval* group of transformations so you don't need to switch to the eval group ;).\n",
    "\n",
    "As noted before, transformations for the current group are loaded in the `transform` and `target_transform` fields. These fields can be changed directly, but this is *NOT* recommended, as this will not create a copy of the dataset and may probably affect other parts of the code in which the dataset is used.\n",
    "\n",
    "The recommended way to switch between the *train* and *eval* groups is to use the `.train()` and `.eval()` methods to obtain a copy (view) of the dataset with the proper transformations enabled. This is another very handy feature of the AvalancheDataset: **methods that manipulate the AvalancheDataset fields (and transformations) always create a view of the dataset. The original dataset is never changed.**\n",
    "\n",
    "In the following cell we use the *avl\\_mnist\\_transform* dataset created in the cells above. We first obtain a view of it in which *eval* transformations are enabled. Then, starting from this view, we obtain a version of it in which *train* transformations are enabled. We want to double-stress that `.train()` and `.eval()` never change the group of the dataset on which they are called: they always create a view.\n",
    "\n",
    "One can check that the correct transformation group is in use by looking at the content of the *transform/target_transform* fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset transformation: Compose(\n",
      "    RandomRotation(degrees=[-45.0, 45.0], interpolation=nearest, expand=False, fill=0)\n",
      "    ToTensor()\n",
      ")\n",
      "--------------------------------\n",
      "Eval version of the dataset: ToTensor()\n",
      "--------------------------------\n",
      "Back to train transformations: Compose(\n",
      "    RandomRotation(degrees=[-45.0, 45.0], interpolation=nearest, expand=False, fill=0)\n",
      "    ToTensor()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Obtain a view of the dataset in which eval transformations are enabled\n",
    "avl_mnist_eval = avl_mnist_transform.eval()\n",
    "\n",
    "# Obtain a view of the dataset in which we get back to train transforms\n",
    "# Basically, avl_mnist_transform ~= avl_mnist_train\n",
    "avl_mnist_train = avl_mnist_eval.train()\n",
    "\n",
    "# Check the current transformations function for the 3 datasets\n",
    "print('Original dataset transformation:', avl_mnist_transform.transform)\n",
    "# Output:\n",
    "# Original dataset transformation: Compose(\n",
    "#     RandomRotation(degrees=[-45.0, 45.0], interpolation=nearest, expand=False, fill=0)\n",
    "#     ToTensor()\n",
    "# )\n",
    "print('--------------------------------')\n",
    "print('Eval version of the dataset:', avl_mnist_eval.transform)\n",
    "# Output: \"Eval version of the dataset: ToTensor()\"\n",
    "print('--------------------------------')\n",
    "print('Back to train transformations:', avl_mnist_train.transform)\n",
    "# Output:\n",
    "# Back to train transformations: Compose(\n",
    "#     RandomRotation(degrees=[-45.0, 45.0], interpolation=nearest, expand=False, fill=0)\n",
    "#     ToTensor()\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom transformation groups\n",
    "In *AvalancheDataset*s the **_train_ and _eval_ transformation groups are always available**. However, *AvalancheDataset* also supports **custom transformation groups**.\n",
    "\n",
    "The following example shows how to create an AvalancheDataset with an additional group named *replay*. We define the replay transformation as a random crop followed by the ToTensor operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<avalanche.benchmarks.utils.avalanche_dataset.AvalancheDataset at 0x7f51d878a970>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(28, padding=4),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "replay_target_transform = None\n",
    "\n",
    "transform_groups_with_replay = {\n",
    "    'train': (None, None),\n",
    "    'eval': (None, None),\n",
    "    'replay': (replay_transform, replay_target_transform)\n",
    "}\n",
    "\n",
    "AvalancheDataset(mnist_dataset, transform_groups=transform_groups_with_replay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, once created the dataset will use the *train* group. There are two ways to **switch to our custom group**:\n",
    "- Set the group when creating the dataset using the `initial_transform_group` constructor parameter\n",
    "- Switch to the group using the `.with_transforms(group_name)` method\n",
    "\n",
    "The `.with_transforms(group_name)` method behaves in the same way `.train()` and `.eval()` do by creating a view of the original dataset.\n",
    "\n",
    "The following example shows how to use both methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    RandomCrop(size=(28, 28), padding=4)\n",
      "    ToTensor()\n",
      ")\n",
      "Compose(\n",
      "    RandomCrop(size=(28, 28), padding=4)\n",
      "    ToTensor()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Method 1: create the dataset with \"replay\" as the default group\n",
    "avl_mnist_custom_transform_1 = AvalancheDataset(\n",
    "    mnist_dataset,\n",
    "    transform_groups=transform_groups_with_replay,\n",
    "    initial_transform_group='replay')\n",
    "\n",
    "print(avl_mnist_custom_transform_1.transform)\n",
    "\n",
    "# Method 2: switch to \"replay\" using `.with_transforms(group_name)`\n",
    "avl_mnist_custom_transform_not_enabled = AvalancheDataset(\n",
    "    mnist_dataset,\n",
    "    transform_groups=transform_groups_with_replay)\n",
    "\n",
    "avl_mnist_custom_transform_2 = avl_mnist_custom_transform_not_enabled.with_transforms('replay')\n",
    "print(avl_mnist_custom_transform_2.transform)\n",
    "\n",
    "# Both prints output:\n",
    "# Compose(\n",
    "#     RandomCrop(size=(28, 28), padding=4)\n",
    "#     ToTensor()\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending transformations\n",
    "\n",
    "In the standard torchvision datasets the only way to append (that is, add a new transformation step to the list of existing one) is to change the *transform* field directly by doing something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    ToTensor()\n",
      "    RandomCrop(size=(28, 28), padding=4)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Append a transform by using torchvision datasets (>>> DON'T DO THIS! <<<)\n",
    "\n",
    "# Create the dataset\n",
    "mnist_dataset_w_totensor = MNIST('mnist_data', download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Append a transform\n",
    "to_append_transform = transforms.RandomCrop(size=(28, 28), padding=4)\n",
    "mnist_dataset_w_totensor.transform = transforms.Compose(\n",
    "    [mnist_dataset_w_totensor.transform, to_append_transform]\n",
    ")\n",
    "print(mnist_dataset_w_totensor.transform)\n",
    "# Prints:\n",
    "# Compose(\n",
    "#     ToTensor()\n",
    "#     RandomCrop(size=(28, 28), padding=4)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This solution has many huge drawbacks:\n",
    "- The transformation field of the dataset is changed directly. This will affect other parts of the code that use that dataset instance.\n",
    "- If the initial transform is `None`, then `Compose` will not complain, but the process will crash later (try it by yourself: replace the first element of Compose in cell above with `None`, then try obtaining a data point from the dataset).\n",
    "- If you need to change transformations only temporarly to do some specific things in a limited part of the code, then you need to store the previous set of transformations in some variable in order to switch back to them later.\n",
    "\n",
    "AvalancheDataset offers a very simple method to append transformations without incurring in those issues. The `.add_transforms(transform=None, target_transform=None)` method will append the given transform(s) **to the currently enabled transform group** and will return a new (a view actually) dataset with given transformations appended to the existing ones. The original dataset is not affected. One can also use `.add_transforms_to_group(group_name, transform, target_transform)` to change transformations for a different group.\n",
    "\n",
    "The next cell shows how to use `.add_transforms(...)` to append the *to\\_append\\_transform* transform defined in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With appended transforms: Compose(\n",
      "    ToTensor()\n",
      "    RandomCrop(size=(28, 28), padding=4)\n",
      ")\n",
      "Original dataset: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "avl_mnist = AvalancheDataset(MNIST('mnist_data', download=True), transform=transforms.ToTensor())\n",
    "\n",
    "# Append a transformation. Simple as:\n",
    "avl_mnist_appended_transform = avl_mnist.add_transforms(to_append_transform)\n",
    "\n",
    "print('With appended transforms:', avl_mnist_appended_transform.transform)\n",
    "# Prints:\n",
    "# With appended transforms: Compose(\n",
    "#     ToTensor()\n",
    "#     RandomCrop(size=(28, 28), padding=4)\n",
    "# )\n",
    "\n",
    "# Check that the original dataset was not affected:\n",
    "print('Original dataset:', avl_mnist.transform)\n",
    "# Prints: \"Original dataset: ToTensor()\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that by using `.add_transforms(...)`:\n",
    "\n",
    "- The original dataset is not changed, which means that other parts of the code that use that dataset instance are not affected.\n",
    "- You don't need to worry about *None* transformations.\n",
    "- In order to revert to the original transformations you don't need to keep a copy of them: the original dataset is not affected!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing transformations\n",
    "\n",
    "The replacement operation follows the same idea (and benefits) of the append one. By using `.replace_transforms(transform, target_transform)` one can obtain a view of the original dataset in which the **transformaations for the current group** are replaced with the given ones. One may also change tranformations for other groups by passing the name of the group as the optional parameter `group`. As with any transform-related operation, the original dataset is not affected. \n",
    "\n",
    "Note: one can use `.replace_transforms(...)` to remove previous transformations (by passing `None` as the new transform).\n",
    "\n",
    "The following cell shows how to use `.replace_transforms(...)` to replace the transformations of the current group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With replaced transform: RandomCrop(size=(28, 28), padding=4)\n",
      "Original dataset: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "new_transform = transforms.RandomCrop(size=(28, 28), padding=4)\n",
    "\n",
    "# Append a transformation. Simple as:\n",
    "avl_mnist_replaced_transform = avl_mnist.replace_transforms(new_transform, None)\n",
    "\n",
    "print('With replaced transform:', avl_mnist_replaced_transform.transform)\n",
    "# Prints: \"With replaces transforms: RandomCrop(size=(28, 28), padding=4)\"\n",
    "\n",
    "# Check that the original dataset was not affected:\n",
    "print('Original dataset:', avl_mnist.transform)\n",
    "# Prints: \"Original dataset: ToTensor()\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freezing transformations\n",
    "\n",
    "One last functionality regarding transformations is the ability to \"freeze\" transformations. Freezing transformations menas **permanently glueing transformations to the dataset so that they can't be replaced or changed in any way** (usually by mistake). Frozen transformations cannot be changed by using `.replace_transforms(...)` or even by changing the `transform` field directly.\n",
    "\n",
    "One may wonder when this may come in handy... in fact, you will probably rarely need to freeze transformations. However, imagine having to instantiate the PermutedMNIST benchmark. You want the permutation transformation to not be changed by mistake. However, the end users do not know how the internal implementations of the benchmark works, so they may end up messing with those transformations. By freezing the permutation transformation, users cannot mess with it.\n",
    "\n",
    "Transformations for all transform groups can be frozen at once by using `.freeze_transforms()`. Transformations can be frozen for a single group by using `.freeze_group_transforms(group_name)`. As always, those methods return a view of the original dataset.\n",
    "\n",
    "The cell below shows a simplified excerpt from the [PermutedMNIST benchmark implementation](https://github.com/ContinualAI/avalanche/blob/master/avalanche/benchmarks/classic/cmnist.py). First, a *PixelsPermutation* instance is created. That instance is a transformation that will permute the pixels of the input image. We then create the train end test sets. Once created, transformations for those datasets are frozen using `.freeze_transforms()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.benchmarks.classic.cmnist import PixelsPermutation\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Instantiate MNIST train and test sets\n",
    "mnist_train = MNIST('mnist_data', train=True, download=True)\n",
    "mnist_test = MNIST('mnist_data', train=False, download=True)\n",
    "    \n",
    "# Define the transformation used to permute the pixels\n",
    "rng_seed = 4321\n",
    "rng_permute = np.random.RandomState(rng_seed)\n",
    "idx_permute = torch.from_numpy(rng_permute.permutation(784)).type(torch.int64)\n",
    "permutation_transform = PixelsPermutation(idx_permute)\n",
    "\n",
    "# Define the transforms group\n",
    "perm_group_transforms = dict(\n",
    "    train=(permutation_transform, None),\n",
    "    eval=(permutation_transform, None)\n",
    ")\n",
    "\n",
    "# Create the datasets and freeze transforms\n",
    "# Note: one can call \"freeze_transforms\" on constructor result\n",
    "# or you can do this in 2 steps. The result is the same (obviously).\n",
    "# The next part show both ways:\n",
    "\n",
    "# Train set\n",
    "permuted_train_set = AvalancheDataset(\n",
    "    mnist_train, \n",
    "    transform_groups=perm_group_transforms).freeze_transforms()\n",
    "\n",
    "# Test set\n",
    "permuted_test_set = AvalancheDataset(\n",
    "    mnist_test, transform_groups=perm_group_transforms, \n",
    "    initial_transform_group='eval')\n",
    "permuted_test_set = permuted_test_set.freeze_transforms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, that transform can't be removed. However, remember that one can always append other transforms atop of frozen transforms.\n",
    "\n",
    "The cell below shows that `replace_transforms` can't remove frozen transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before replace_transforms:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMAAAADACAAAAAB3tzPbAAAEP0lEQVR4nO2dTYhOYRTHzzWDBTFZ+WrIR5ShJoXU1DRKkYXJR1HKyoJZKQtNEeWjpqywkCLKAg2lEJms1IiUYSULFpjNGKLJ51j8z9Q9t+e997kz7+u8p85v8+957vP179TpPu99n3sTEvxJF/pFXRtF0gHpi23/BTKzsCEvpEGUJsVOU6+4AW3cgDbmDSQyN7VDHqXrmI2QZ5AhyDfI9Njp5Gyi7gmkrbChXJb5CLgBbdyANuYNNMqk9BgiKpdAHoS6R+dP5lSgriFQl2FruqHMpuYj4Aa0cQPamDeQRLdcAXkNkbnsAhER7cvpfROyPXCpFbIAcrvyGL8gk0Wl+Qi4AW3cgDZJO7QXMit9TWaaUe5Qeax7kE2ha8H9rKi7A9lcefwg5iPgBrRxA9qYN5DJinchZXPZPCIieo9CxB53fPATo7UQzvjmI+AGtHED2pg3EL8nZq5Bdhc2nAbZBrlS2J5/utwAic7F5iPgBrRxA9qYNxCRRvdALkEGIbMhfIO4vnAQuanvISKig6JF2ZvYZRDzEXAD2rgBbcwbCKdRJL0a7M5zfiKN5hWkBWI+Am5AGzegjXkDjbJ4GrIj0PI6ZGdolOK0WzZ/roK8DFxqESXzEXAD2rgBbcwbyNyN8k+e+AH0BQqtoX68IT8DmUNERB9R6ITcqs4CU7yDzIf43y7rBDegjXkD1dwTv4EsFZUXIYsgfEzxCBERHQ/MGT/pD4j5CLgBbdyANuYNjB1F5F1wb+WWbPUv5CtkRvVWMhfyIba9n+iuE9yANm5Am2QY2lSyX+g84BYUnkI+xQ7FUw+XXAGlpzaMG9DGDWhj3kDpv11KJvTgegSyEDI4vhWYj4Ab0MYNaGPeQEQa5Scu9yEj4hqfxDlERESHS86dl4MPQM5BmomIaBcKJ0U38xFwA9q4AW3MG5jg3WjZeX5DRObks5H9oW58PLO58sDmI+AGtHED2pg3EE6jsMVPk9ZBBiDfQ+2PEhHRsSquKwQ/z/oM8bvROsENaGPeQBL946Bs+ByyumQ3BlvpIdGCYhfC+FHEOsENaOMGtKnBnjiYOFdCBqo+m/kIuAFt3IA25g00FjcpS0+oMpQ/b0BC5x7z8FeX1xduQBs3oE1yAtpd2LIJMlyrlfDRxc6S3cxHwA1o4wa0MW8gs6k/D9lPRNV5GVA8/HbM4BOgHMxHwA1o4wa0MW8gk0ZzMuf/TarRmI+AG9DGDWhj3kDt/nb5ELIGUvwJcUZm68uQvUQ09tWzzGfPzEfADWjjBrTJZKHFkLeF/XJu7fhV51ch/BIhvFFIvoKoD4WOwhHzMB8BN6CNG9DGvIGIPXHwHkqCT8fKL8fyyKOFS+DP1S4XlcXZlFO9+Qi4AW3cgDbmDYylUT6aPVTY4SdkCuQspCvdoktckvArKqem6/JuQ8U1fucuf8ybj5abj4Ab0MYNaGPewD8mbYqJbB1JxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=192x192 at 0x7F50C0FE5DC0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After replace_transforms:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMAAAADACAAAAAB3tzPbAAAEP0lEQVR4nO2dTYhOYRTHzzWDBTFZ+WrIR5ShJoXU1DRKkYXJR1HKyoJZKQtNEeWjpqywkCLKAg2lEJms1IiUYSULFpjNGKLJ51j8z9Q9t+e997kz7+u8p85v8+957vP179TpPu99n3sTEvxJF/pFXRtF0gHpi23/BTKzsCEvpEGUJsVOU6+4AW3cgDbmDSQyN7VDHqXrmI2QZ5AhyDfI9Njp5Gyi7gmkrbChXJb5CLgBbdyANuYNNMqk9BgiKpdAHoS6R+dP5lSgriFQl2FruqHMpuYj4Aa0cQPamDeQRLdcAXkNkbnsAhER7cvpfROyPXCpFbIAcrvyGL8gk0Wl+Qi4AW3cgDZJO7QXMit9TWaaUe5Qeax7kE2ha8H9rKi7A9lcefwg5iPgBrRxA9qYN5DJinchZXPZPCIieo9CxB53fPATo7UQzvjmI+AGtHED2pg3EL8nZq5Bdhc2nAbZBrlS2J5/utwAic7F5iPgBrRxA9qYNxCRRvdALkEGIbMhfIO4vnAQuanvISKig6JF2ZvYZRDzEXAD2rgBbcwbCKdRJL0a7M5zfiKN5hWkBWI+Am5AGzegjXkDjbJ4GrIj0PI6ZGdolOK0WzZ/roK8DFxqESXzEXAD2rgBbcwbyNyN8k+e+AH0BQqtoX68IT8DmUNERB9R6ITcqs4CU7yDzIf43y7rBDegjXkD1dwTv4EsFZUXIYsgfEzxCBERHQ/MGT/pD4j5CLgBbdyANuYNjB1F5F1wb+WWbPUv5CtkRvVWMhfyIba9n+iuE9yANm5Am2QY2lSyX+g84BYUnkI+xQ7FUw+XXAGlpzaMG9DGDWhj3kDpv11KJvTgegSyEDI4vhWYj4Ab0MYNaGPeQEQa5Scu9yEj4hqfxDlERESHS86dl4MPQM5BmomIaBcKJ0U38xFwA9q4AW3MG5jg3WjZeX5DRObks5H9oW58PLO58sDmI+AGtHED2pg3EE6jsMVPk9ZBBiDfQ+2PEhHRsSquKwQ/z/oM8bvROsENaGPeQBL946Bs+ByyumQ3BlvpIdGCYhfC+FHEOsENaOMGtKnBnjiYOFdCBqo+m/kIuAFt3IA25g00FjcpS0+oMpQ/b0BC5x7z8FeX1xduQBs3oE1yAtpd2LIJMlyrlfDRxc6S3cxHwA1o4wa0MW8gs6k/D9lPRNV5GVA8/HbM4BOgHMxHwA1o4wa0MW8gk0ZzMuf/TarRmI+AG9DGDWhj3kDt/nb5ELIGUvwJcUZm68uQvUQ09tWzzGfPzEfADWjjBrTJZKHFkLeF/XJu7fhV51ch/BIhvFFIvoKoD4WOwhHzMB8BN6CNG9DGvIGIPXHwHkqCT8fKL8fyyKOFS+DP1S4XlcXZlFO9+Qi4AW3cgDbmDYylUT6aPVTY4SdkCuQspCvdoktckvArKqem6/JuQ8U1fucuf8ybj5abj4Ab0MYNaGPewD8mbYqJbB1JxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=192x192 at 0x7F50C0FE5820>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMAAAADACAAAAAB3tzPbAAAEP0lEQVR4nO2dTYhOYRTHzzWDBTFZ+WrIR5ShJoXU1DRKkYXJR1HKyoJZKQtNEeWjpqywkCLKAg2lEJms1IiUYSULFpjNGKLJ51j8z9Q9t+e997kz7+u8p85v8+957vP179TpPu99n3sTEvxJF/pFXRtF0gHpi23/BTKzsCEvpEGUJsVOU6+4AW3cgDbmDSQyN7VDHqXrmI2QZ5AhyDfI9Njp5Gyi7gmkrbChXJb5CLgBbdyANuYNNMqk9BgiKpdAHoS6R+dP5lSgriFQl2FruqHMpuYj4Aa0cQPamDeQRLdcAXkNkbnsAhER7cvpfROyPXCpFbIAcrvyGL8gk0Wl+Qi4AW3cgDZJO7QXMit9TWaaUe5Qeax7kE2ha8H9rKi7A9lcefwg5iPgBrRxA9qYN5DJinchZXPZPCIieo9CxB53fPATo7UQzvjmI+AGtHED2pg3EL8nZq5Bdhc2nAbZBrlS2J5/utwAic7F5iPgBrRxA9qYNxCRRvdALkEGIbMhfIO4vnAQuanvISKig6JF2ZvYZRDzEXAD2rgBbcwbCKdRJL0a7M5zfiKN5hWkBWI+Am5AGzegjXkDjbJ4GrIj0PI6ZGdolOK0WzZ/roK8DFxqESXzEXAD2rgBbcwbyNyN8k+e+AH0BQqtoX68IT8DmUNERB9R6ITcqs4CU7yDzIf43y7rBDegjXkD1dwTv4EsFZUXIYsgfEzxCBERHQ/MGT/pD4j5CLgBbdyANuYNjB1F5F1wb+WWbPUv5CtkRvVWMhfyIba9n+iuE9yANm5Am2QY2lSyX+g84BYUnkI+xQ7FUw+XXAGlpzaMG9DGDWhj3kDpv11KJvTgegSyEDI4vhWYj4Ab0MYNaGPeQEQa5Scu9yEj4hqfxDlERESHS86dl4MPQM5BmomIaBcKJ0U38xFwA9q4AW3MG5jg3WjZeX5DRObks5H9oW58PLO58sDmI+AGtHED2pg3EE6jsMVPk9ZBBiDfQ+2PEhHRsSquKwQ/z/oM8bvROsENaGPeQBL946Bs+ByyumQ3BlvpIdGCYhfC+FHEOsENaOMGtKnBnjiYOFdCBqo+m/kIuAFt3IA25g00FjcpS0+oMpQ/b0BC5x7z8FeX1xduQBs3oE1yAtpd2LIJMlyrlfDRxc6S3cxHwA1o4wa0MW8gs6k/D9lPRNV5GVA8/HbM4BOgHMxHwA1o4wa0MW8gk0ZzMuf/TarRmI+AG9DGDWhj3kDt/nb5ELIGUvwJcUZm68uQvUQ09tWzzGfPzEfADWjjBrTJZKHFkLeF/XJu7fhV51ch/BIhvFFIvoKoD4WOwhHzMB8BN6CNG9DGvIGIPXHwHkqCT8fKL8fyyKOFS+DP1S4XlcXZlFO9+Qi4AW3cgDbmDYylUT6aPVTY4SdkCuQspCvdoktckvArKqem6/JuQ8U1fucuf8ybj5abj4Ab0MYNaGPewD8mbYqJbB1JxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=192x192 at 0x7F50C0FE5DC0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, show that the image pixels are permuted\n",
    "print('Before replace_transforms:')\n",
    "display(permuted_train_set[0][0].resize((192, 192), 0))\n",
    "\n",
    "# Try to remove the permutation\n",
    "with_removed_transforms = permuted_train_set.replace_transforms(None, None)\n",
    "\n",
    "print('After replace_transforms:')\n",
    "display(permuted_train_set[0][0].resize((192, 192), 0))\n",
    "display(with_removed_transforms[0][0].resize((192, 192), 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations wrap-up\n",
    "This completes the *Mini How-To* for the functionalities of the *AvalancheDataset* related to **transformations**. \n",
    "\n",
    "Here you learned how to use **transformation groups** and how to **append/replace/freeze transformations** in a simple way.\n",
    "\n",
    "Other *Mini How-To*s will guide you through the other functionalities offered by the *AvalancheDataset* class. The list of *Mini How-To*s can be found [here](https://avalanche.continualai.org/how-tos/avalanchedataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ü§ù Run it on Google Colab\n",
    "\n",
    "You can run _this chapter_ and play with it on Google Colaboratory by clicking here: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ContinualAI/avalanche/blob/master/notebooks/how-tos/avalanchedataset/advanced-transformations.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
