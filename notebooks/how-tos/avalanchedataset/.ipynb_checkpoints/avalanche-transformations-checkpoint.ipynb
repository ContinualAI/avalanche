{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d6e4dc7",
   "metadata": {},
   "source": [
    "---\n",
    "description: Dealing with transformations (groups, appending, replacing, freezing).\n",
    "---\n",
    "\n",
    "# Advanced Transformations\n",
    "While torchvision (and other) datasets typically have a fixed set of transformations, AvalancheDataset also provides some additional functionalities. `AvalancheDataset`s can:\n",
    "1. Have multiple **transformation \"groups\"** in the same dataset (like separate train and eval transformations).\n",
    "2. Manipulate transformation by **freezing, replacing and removing** them.\n",
    "\n",
    "The following sub-sections show examples on how to use these features.\n",
    "It is warmly recommended to **run this page as a notebook** using Colab (info at the bottom of this page).\n",
    "\n",
    "Let's start by installing Avalanche:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1fec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install avalanche-lib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9653e7",
   "metadata": {},
   "source": [
    "## Transformation groups\n",
    "AvalancheDatasets can contain multiple **transformation groups**. This can be useful to keep train and test transformations in the same dataset and to have different sets of transformations. For instance, you can easily add ad-hoc transformations to using for replay data.\n",
    "\n",
    "For classification dataset, we follow torchvision conventions. Therefore, `make_classification_dataset` supports `transform`, which is applied to input (X) values, and `target_transform`, which is applied to class labels (Y). The latter is rarely used. This means that **a transformation group is a pair of transformations to be applied to the X and Y values** of each instance returned by the dataset. In both torchvision and Avalanche implementations, **a transformation must be a function (or other callable object)** that accepts one input (the X or Y value) and outputs its transformed version. A comprehensive guide on transformations can be found in the [torchvision documentation](https://pytorch.org/vision/stable/transforms.html).\n",
    "\n",
    "In the following example, a MNIST dataset is created and then wrapped in an AvalancheDataset. When creating the AvalancheDataset, we can set *train* and *eval* transformations by passing a *transform\\_groups* parameter. Train transformations usually include some form of random augmentation, while eval transformations usually include a sequence of deterministic transformations only. Here we define the sequence of train transformations as a random rotation followed by the ToTensor operation. The eval transformations only include the ToTensor operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29657c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from avalanche.benchmarks.utils import make_classification_dataset\n",
    "\n",
    "mnist_dataset = MNIST('mnist_data', download=True)\n",
    "\n",
    "# Define the training transformation for X values\n",
    "train_transformation = transforms.Compose([\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "# Define the training transformation for Y values (rarely used)\n",
    "train_target_transformation = None\n",
    "\n",
    "# Define the test transformation for X values\n",
    "eval_transformation = transforms.ToTensor()\n",
    "# Define the test transformation for Y values (rarely used)\n",
    "eval_target_transformation = None\n",
    "\n",
    "transform_groups = {\n",
    "    'train': (train_transformation, train_target_transformation),\n",
    "    'eval': (eval_transformation, eval_target_transformation)\n",
    "}\n",
    "\n",
    "avl_mnist_transform = make_classification_dataset(mnist_dataset, transform_groups=transform_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66782fcf",
   "metadata": {},
   "source": [
    "Of course, one can also just use the `transform` and `target_transform` constructor parameters to set the transformations for both the *train* and the *eval* groups. However, it is recommended to use the approach based on *transform\\_groups* (shown in the code above) as it is much more flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2705fa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not recommended: use transform_groups instead\n",
    "avl_mnist_same_transforms =  make_classification_dataset(mnist_dataset, transform=train_transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6449c62c",
   "metadata": {},
   "source": [
    "### Using `.train()` and `.eval()`\n",
    "\n",
    "**The default behaviour of the AvalancheDataset is to use transformations from the _train_ group.** However, one can easily obtain a version of the dataset where the *eval* group is used. Note: when obtaining the dataset of experiences from the test stream, those datasets will already be using the *eval* group of transformations so you don't need to switch to the eval group ;).\n",
    "\n",
    "You can switch between the *train* and *eval* groups using the `.train()` and `.eval()` methods to obtain a copy (view) of the dataset with the proper transformations enabled. As a general rule, **methods that manipulate the AvalancheDataset fields (and transformations) always create a view of the dataset. The original dataset is never changed.**\n",
    "\n",
    "In the following cell we use the *avl\\_mnist\\_transform* dataset created in the cells above. We first obtain a view of it in which *eval* transformations are enabled. Then, starting from this view, we obtain a version of it in which *train* transformations are enabled. We want to double-stress that `.train()` and `.eval()` never change the group of the dataset on which they are called: they always create a view.\n",
    "\n",
    "One can check that the correct transformation group is in use by looking at the content of the *transform/target_transform* fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f86f591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset transformations: (train group by default)\n",
      "TupleTransform((Compose(\n",
      "    RandomRotation(degrees=[-45.0, 45.0], interpolation=nearest, expand=False, fill=0)\n",
      "    ToTensor()\n",
      "), None))\n",
      "\n",
      "eval mode dataset transformations:\n",
      "TupleTransform((ToTensor(), None))\n",
      "\n",
      "train mode dataset transformations:\n",
      "TupleTransform((Compose(\n",
      "    RandomRotation(degrees=[-45.0, 45.0], interpolation=nearest, expand=False, fill=0)\n",
      "    ToTensor()\n",
      "), None))\n"
     ]
    }
   ],
   "source": [
    "# Obtain a view of the dataset in which eval transformations are enabled\n",
    "avl_mnist_eval = avl_mnist_transform.eval()\n",
    "\n",
    "# Obtain a view of the dataset in which we get back to train transforms\n",
    "# Basically, avl_mnist_transform ~= avl_mnist_train\n",
    "avl_mnist_train = avl_mnist_eval.train()\n",
    "\n",
    "# we are looking inside the dataset to check the transformations.\n",
    "# in real code, you never need to do this ;)\n",
    "cgroup = avl_mnist_train._transform_groups.current_group\n",
    "print(\"Original dataset transformations: (train group by default)\")\n",
    "# notice that the original transform are unchanged.\n",
    "print(avl_mnist_train._transform_groups.transform_groups[cgroup])\n",
    "\n",
    "print(\"\\neval mode dataset transformations:\")\n",
    "cgroup = avl_mnist_eval._transform_groups.current_group\n",
    "print(avl_mnist_eval._transform_groups.transform_groups[cgroup])\n",
    "\n",
    "print(\"\\ntrain mode dataset transformations:\")\n",
    "cgroup = avl_mnist_train._transform_groups.current_group\n",
    "print(avl_mnist_train._transform_groups.transform_groups[cgroup])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710b8792",
   "metadata": {},
   "source": [
    "### Custom transformation groups\n",
    "In *AvalancheDataset*s the **_train_ and _eval_ transformation groups are always available**. However, *AvalancheDataset* also supports **custom transformation groups**.\n",
    "\n",
    "The following example shows how to create an AvalancheDataset with an additional group named *replay*. We define the replay transformation as a random crop followed by the ToTensor operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48335b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<avalanche.benchmarks.utils.data.AvalancheDataset at 0x288344a1fa0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from avalanche.benchmarks.utils import AvalancheDataset\n",
    "\n",
    "replay_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(28, padding=4),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "replay_target_transform = None\n",
    "\n",
    "transform_groups_with_replay = {\n",
    "    'train': (None, None),\n",
    "    'eval': (None, None),\n",
    "    'replay': (replay_transform, replay_target_transform)\n",
    "}\n",
    "\n",
    "AvalancheDataset(mnist_dataset, transform_groups=transform_groups_with_replay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83f78bf",
   "metadata": {},
   "source": [
    "However, once created the dataset will use the *train* group. You can switch to the group using the `.with_transforms(group_name)` method. The `.with_transforms(group_name)` method behaves in the same way `.train()` and `.eval()` do by creating a view of the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6533faeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TupleTransform((Compose(\n",
      "    RandomCrop(size=(28, 28), padding=4)\n",
      "    ToTensor()\n",
      "), None))\n"
     ]
    }
   ],
   "source": [
    "avl_mnist_custom_transform_not_enabled = AvalancheDataset(\n",
    "    mnist_dataset,\n",
    "    transform_groups=transform_groups_with_replay)\n",
    "\n",
    "avl_mnist_custom_transform_2 = avl_mnist_custom_transform_not_enabled.with_transforms('replay')\n",
    "cgroup = avl_mnist_custom_transform_2._transform_groups.current_group\n",
    "print(avl_mnist_custom_transform_2._transform_groups.transform_groups[cgroup])\n",
    "\n",
    "# prints output:\n",
    "# Compose(\n",
    "#     RandomCrop(size=(28, 28), padding=4)\n",
    "#     ToTensor()\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb56d8a",
   "metadata": {},
   "source": [
    "## Replacing transformations\n",
    "\n",
    "The replacement operation follows the same idea (and benefits) of the append one. By using `.replace_current_transform_group(transform, target_transform)` one can obtain a view of the original dataset in which the **transformaations for the current group** are replaced with the given ones. One may also change tranformations for other groups by passing the name of the group as the optional parameter `group`. As with any transform-related operation, the original dataset is not affected. \n",
    "\n",
    "Note: one can use `.replace_transforms(...)` to remove previous transformations (by passing `None` as the new transform).\n",
    "\n",
    "The following cell shows how to use `.replace_transforms(...)` to replace the transformations of the current group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "249912b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With replaced transform: TupleTransform((RandomCrop(size=(28, 28), padding=4), None))\n",
      "Original dataset: TupleTransform((Compose(\n",
      "    RandomRotation(degrees=[-45.0, 45.0], interpolation=nearest, expand=False, fill=0)\n",
      "    ToTensor()\n",
      "), None))\n"
     ]
    }
   ],
   "source": [
    "avl_mnist = make_classification_dataset(mnist_dataset, transform_groups=transform_groups)\n",
    "new_transform = transforms.RandomCrop(size=(28, 28), padding=4)\n",
    "\n",
    "# Append a transformation. Simple as:\n",
    "transform = (new_transform, None)\n",
    "avl_mnist_replaced_transform = avl_mnist.replace_current_transform_group(transform)\n",
    "\n",
    "cgroup = avl_mnist_replaced_transform._transform_groups.current_group\n",
    "print('With replaced transform:', avl_mnist_replaced_transform._transform_groups.transform_groups[cgroup])\n",
    "# Prints: \"With replaces transforms: RandomCrop(size=(28, 28), padding=4)\"\n",
    "\n",
    "# Check that the original dataset was not affected:\n",
    "cgroup = avl_mnist._transform_groups.current_group\n",
    "print('Original dataset:', avl_mnist._transform_groups.transform_groups[cgroup])\n",
    "# Prints: \"Original dataset: ToTensor()\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e934a78f",
   "metadata": {},
   "source": [
    "## Freezing transformations\n",
    "\n",
    "One last functionality regarding transformations is the ability to \"freeze\" transformations. Freezing transformations menas **permanently glueing transformations to the dataset so that they can't be replaced or changed in any way** (usually by mistake). Frozen transformations cannot be changed by using `.replace_transforms(...)`.\n",
    "\n",
    "One may wonder when this may come in handy... in fact, you will probably rarely need to freeze transformations. However, imagine having to instantiate the PermutedMNIST benchmark. You want the permutation transformation to not be changed by mistake. However, the end users do not know how the internal implementations of the benchmark works, so they may end up messing with those transformations. By freezing the permutation transformation, users cannot mess with it.\n",
    "\n",
    "Transformations for all transform groups can be frozen at once by using `.freeze_transforms()`. As always, those methods return a view of the original dataset.\n",
    "\n",
    "The cell below shows a simplified excerpt from the [PermutedMNIST benchmark implementation](https://github.com/ContinualAI/avalanche/blob/master/avalanche/benchmarks/classic/cmnist.py). First, a *PixelsPermutation* instance is created. That instance is a transformation that will permute the pixels of the input image. We then create the train end test sets. Once created, transformations for those datasets are frozen using `.freeze_transforms()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7db17f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.benchmarks.classic.cmnist import PixelsPermutation\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Instantiate MNIST train and test sets\n",
    "mnist_train = MNIST('mnist_data', train=True, download=True)\n",
    "mnist_test = MNIST('mnist_data', train=False, download=True)\n",
    "    \n",
    "# Define the transformation used to permute the pixels\n",
    "rng_seed = 4321\n",
    "rng_permute = np.random.RandomState(rng_seed)\n",
    "idx_permute = torch.from_numpy(rng_permute.permutation(784)).type(torch.int64)\n",
    "permutation_transform = PixelsPermutation(idx_permute)\n",
    "\n",
    "# Define the transforms group\n",
    "perm_group_transforms = dict(\n",
    "    train=(permutation_transform, None),\n",
    "    eval=(permutation_transform, None)\n",
    ")\n",
    "\n",
    "# Create the datasets and freeze transforms\n",
    "# Note: one can call \"freeze_transforms\" on constructor result\n",
    "# or you can do this in 2 steps. The result is the same (obviously).\n",
    "# The next part show both ways:\n",
    "\n",
    "# Train set\n",
    "permuted_train_set = AvalancheDataset(\n",
    "    mnist_train, \n",
    "    transform_groups=perm_group_transforms).freeze_transforms()\n",
    "\n",
    "# Test set\n",
    "permuted_test_set = AvalancheDataset(mnist_test, transform_groups=perm_group_transforms).eval()\n",
    "permuted_test_set = permuted_test_set.freeze_transforms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb16f371",
   "metadata": {},
   "source": [
    "In this way, that transform can't be removed. However, remember that one can always append other transforms atop of frozen transforms.\n",
    "\n",
    "The cell below shows that `replace_transforms` can't remove frozen transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03337801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before replace_transforms:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMAAAADACAAAAAB3tzPbAAAEP0lEQVR4nO2dTYhOYRTHzzWDBTFZ+WrIR5ShJoXU1DRKkYXJR1HKyoJZKQtNEeWjpqywkCLKAg2lEJms1IiUYSULFpjNGKLJ51j8z9Q9t+e997kz7+u8p85v8+957vP179TpPu99n3sTEvxJF/pFXRtF0gHpi23/BTKzsCEvpEGUJsVOU6+4AW3cgDbmDSQyN7VDHqXrmI2QZ5AhyDfI9Njp5Gyi7gmkrbChXJb5CLgBbdyANuYNNMqk9BgiKpdAHoS6R+dP5lSgriFQl2FruqHMpuYj4Aa0cQPamDeQRLdcAXkNkbnsAhER7cvpfROyPXCpFbIAcrvyGL8gk0Wl+Qi4AW3cgDZJO7QXMit9TWaaUe5Qeax7kE2ha8H9rKi7A9lcefwg5iPgBrRxA9qYN5DJinchZXPZPCIieo9CxB53fPATo7UQzvjmI+AGtHED2pg3EL8nZq5Bdhc2nAbZBrlS2J5/utwAic7F5iPgBrRxA9qYNxCRRvdALkEGIbMhfIO4vnAQuanvISKig6JF2ZvYZRDzEXAD2rgBbcwbCKdRJL0a7M5zfiKN5hWkBWI+Am5AGzegjXkDjbJ4GrIj0PI6ZGdolOK0WzZ/roK8DFxqESXzEXAD2rgBbcwbyNyN8k+e+AH0BQqtoX68IT8DmUNERB9R6ITcqs4CU7yDzIf43y7rBDegjXkD1dwTv4EsFZUXIYsgfEzxCBERHQ/MGT/pD4j5CLgBbdyANuYNjB1F5F1wb+WWbPUv5CtkRvVWMhfyIba9n+iuE9yANm5Am2QY2lSyX+g84BYUnkI+xQ7FUw+XXAGlpzaMG9DGDWhj3kDpv11KJvTgegSyEDI4vhWYj4Ab0MYNaGPeQEQa5Scu9yEj4hqfxDlERESHS86dl4MPQM5BmomIaBcKJ0U38xFwA9q4AW3MG5jg3WjZeX5DRObks5H9oW58PLO58sDmI+AGtHED2pg3EE6jsMVPk9ZBBiDfQ+2PEhHRsSquKwQ/z/oM8bvROsENaGPeQBL946Bs+ByyumQ3BlvpIdGCYhfC+FHEOsENaOMGtKnBnjiYOFdCBqo+m/kIuAFt3IA25g00FjcpS0+oMpQ/b0BC5x7z8FeX1xduQBs3oE1yAtpd2LIJMlyrlfDRxc6S3cxHwA1o4wa0MW8gs6k/D9lPRNV5GVA8/HbM4BOgHMxHwA1o4wa0MW8gk0ZzMuf/TarRmI+AG9DGDWhj3kDt/nb5ELIGUvwJcUZm68uQvUQ09tWzzGfPzEfADWjjBrTJZKHFkLeF/XJu7fhV51ch/BIhvFFIvoKoD4WOwhHzMB8BN6CNG9DGvIGIPXHwHkqCT8fKL8fyyKOFS+DP1S4XlcXZlFO9+Qi4AW3cgDbmDYylUT6aPVTY4SdkCuQspCvdoktckvArKqem6/JuQ8U1fucuf8ybj5abj4Ab0MYNaGPewD8mbYqJbB1JxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=192x192 at 0x28834494910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After replace_transforms:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMAAAADACAAAAAB3tzPbAAAEP0lEQVR4nO2dTYhOYRTHzzWDBTFZ+WrIR5ShJoXU1DRKkYXJR1HKyoJZKQtNEeWjpqywkCLKAg2lEJms1IiUYSULFpjNGKLJ51j8z9Q9t+e997kz7+u8p85v8+957vP179TpPu99n3sTEvxJF/pFXRtF0gHpi23/BTKzsCEvpEGUJsVOU6+4AW3cgDbmDSQyN7VDHqXrmI2QZ5AhyDfI9Njp5Gyi7gmkrbChXJb5CLgBbdyANuYNNMqk9BgiKpdAHoS6R+dP5lSgriFQl2FruqHMpuYj4Aa0cQPamDeQRLdcAXkNkbnsAhER7cvpfROyPXCpFbIAcrvyGL8gk0Wl+Qi4AW3cgDZJO7QXMit9TWaaUe5Qeax7kE2ha8H9rKi7A9lcefwg5iPgBrRxA9qYN5DJinchZXPZPCIieo9CxB53fPATo7UQzvjmI+AGtHED2pg3EL8nZq5Bdhc2nAbZBrlS2J5/utwAic7F5iPgBrRxA9qYNxCRRvdALkEGIbMhfIO4vnAQuanvISKig6JF2ZvYZRDzEXAD2rgBbcwbCKdRJL0a7M5zfiKN5hWkBWI+Am5AGzegjXkDjbJ4GrIj0PI6ZGdolOK0WzZ/roK8DFxqESXzEXAD2rgBbcwbyNyN8k+e+AH0BQqtoX68IT8DmUNERB9R6ITcqs4CU7yDzIf43y7rBDegjXkD1dwTv4EsFZUXIYsgfEzxCBERHQ/MGT/pD4j5CLgBbdyANuYNjB1F5F1wb+WWbPUv5CtkRvVWMhfyIba9n+iuE9yANm5Am2QY2lSyX+g84BYUnkI+xQ7FUw+XXAGlpzaMG9DGDWhj3kDpv11KJvTgegSyEDI4vhWYj4Ab0MYNaGPeQEQa5Scu9yEj4hqfxDlERESHS86dl4MPQM5BmomIaBcKJ0U38xFwA9q4AW3MG5jg3WjZeX5DRObks5H9oW58PLO58sDmI+AGtHED2pg3EE6jsMVPk9ZBBiDfQ+2PEhHRsSquKwQ/z/oM8bvROsENaGPeQBL946Bs+ByyumQ3BlvpIdGCYhfC+FHEOsENaOMGtKnBnjiYOFdCBqo+m/kIuAFt3IA25g00FjcpS0+oMpQ/b0BC5x7z8FeX1xduQBs3oE1yAtpd2LIJMlyrlfDRxc6S3cxHwA1o4wa0MW8gs6k/D9lPRNV5GVA8/HbM4BOgHMxHwA1o4wa0MW8gk0ZzMuf/TarRmI+AG9DGDWhj3kDt/nb5ELIGUvwJcUZm68uQvUQ09tWzzGfPzEfADWjjBrTJZKHFkLeF/XJu7fhV51ch/BIhvFFIvoKoD4WOwhHzMB8BN6CNG9DGvIGIPXHwHkqCT8fKL8fyyKOFS+DP1S4XlcXZlFO9+Qi4AW3cgDbmDYylUT6aPVTY4SdkCuQspCvdoktckvArKqem6/JuQ8U1fucuf8ybj5abj4Ab0MYNaGPewD8mbYqJbB1JxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=192x192 at 0x28833032700>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMAAAADACAAAAAB3tzPbAAAEP0lEQVR4nO2dTYhOYRTHzzWDBTFZ+WrIR5ShJoXU1DRKkYXJR1HKyoJZKQtNEeWjpqywkCLKAg2lEJms1IiUYSULFpjNGKLJ51j8z9Q9t+e997kz7+u8p85v8+957vP179TpPu99n3sTEvxJF/pFXRtF0gHpi23/BTKzsCEvpEGUJsVOU6+4AW3cgDbmDSQyN7VDHqXrmI2QZ5AhyDfI9Njp5Gyi7gmkrbChXJb5CLgBbdyANuYNNMqk9BgiKpdAHoS6R+dP5lSgriFQl2FruqHMpuYj4Aa0cQPamDeQRLdcAXkNkbnsAhER7cvpfROyPXCpFbIAcrvyGL8gk0Wl+Qi4AW3cgDZJO7QXMit9TWaaUe5Qeax7kE2ha8H9rKi7A9lcefwg5iPgBrRxA9qYN5DJinchZXPZPCIieo9CxB53fPATo7UQzvjmI+AGtHED2pg3EL8nZq5Bdhc2nAbZBrlS2J5/utwAic7F5iPgBrRxA9qYNxCRRvdALkEGIbMhfIO4vnAQuanvISKig6JF2ZvYZRDzEXAD2rgBbcwbCKdRJL0a7M5zfiKN5hWkBWI+Am5AGzegjXkDjbJ4GrIj0PI6ZGdolOK0WzZ/roK8DFxqESXzEXAD2rgBbcwbyNyN8k+e+AH0BQqtoX68IT8DmUNERB9R6ITcqs4CU7yDzIf43y7rBDegjXkD1dwTv4EsFZUXIYsgfEzxCBERHQ/MGT/pD4j5CLgBbdyANuYNjB1F5F1wb+WWbPUv5CtkRvVWMhfyIba9n+iuE9yANm5Am2QY2lSyX+g84BYUnkI+xQ7FUw+XXAGlpzaMG9DGDWhj3kDpv11KJvTgegSyEDI4vhWYj4Ab0MYNaGPeQEQa5Scu9yEj4hqfxDlERESHS86dl4MPQM5BmomIaBcKJ0U38xFwA9q4AW3MG5jg3WjZeX5DRObks5H9oW58PLO58sDmI+AGtHED2pg3EE6jsMVPk9ZBBiDfQ+2PEhHRsSquKwQ/z/oM8bvROsENaGPeQBL946Bs+ByyumQ3BlvpIdGCYhfC+FHEOsENaOMGtKnBnjiYOFdCBqo+m/kIuAFt3IA25g00FjcpS0+oMpQ/b0BC5x7z8FeX1xduQBs3oE1yAtpd2LIJMlyrlfDRxc6S3cxHwA1o4wa0MW8gs6k/D9lPRNV5GVA8/HbM4BOgHMxHwA1o4wa0MW8gk0ZzMuf/TarRmI+AG9DGDWhj3kDt/nb5ELIGUvwJcUZm68uQvUQ09tWzzGfPzEfADWjjBrTJZKHFkLeF/XJu7fhV51ch/BIhvFFIvoKoD4WOwhHzMB8BN6CNG9DGvIGIPXHwHkqCT8fKL8fyyKOFS+DP1S4XlcXZlFO9+Qi4AW3cgDbmDYylUT6aPVTY4SdkCuQspCvdoktckvArKqem6/JuQ8U1fucuf8ybj5abj4Ab0MYNaGPewD8mbYqJbB1JxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=192x192 at 0x28832EF7D00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, show that the image pixels are permuted\n",
    "print('Before replace_transforms:')\n",
    "display(permuted_train_set[0][0].resize((192, 192), 0))\n",
    "\n",
    "# Try to remove the permutation\n",
    "with_removed_transforms = permuted_train_set.replace_current_transform_group((None, None))\n",
    "\n",
    "print('After replace_transforms:')\n",
    "display(permuted_train_set[0][0].resize((192, 192), 0))\n",
    "display(with_removed_transforms[0][0].resize((192, 192), 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829ffe23",
   "metadata": {},
   "source": [
    "## Transformations wrap-up\n",
    "This completes the *Mini How-To* for the functionalities of the *AvalancheDataset* related to **transformations**. \n",
    "\n",
    "Here you learned how to use **transformation groups** and how to **append/replace/freeze transformations** in a simple way.\n",
    "\n",
    "Other *Mini How-To*s will guide you through the other functionalities offered by the *AvalancheDataset* class. The list of *Mini How-To*s can be found [here](https://avalanche.continualai.org/how-tos/avalanchedataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27af551f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 🤝 Run it on Google Colab\n",
    "\n",
    "You can run _this chapter_ and play with it on Google Colaboratory by clicking here: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ContinualAI/avalanche/blob/master/notebooks/how-tos/avalanchedataset/advanced-transformations.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
